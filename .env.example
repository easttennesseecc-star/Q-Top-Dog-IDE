# Q-IDE Environment Variables
# Copy this file to .env.development or .env.production and fill in your values
# NEVER commit actual .env files to git

# ============ Backend Configuration ============
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
BACKEND_URL=http://127.0.0.1:8000
FRONTEND_URL=http://localhost:1431

# ============ OAuth Configuration ============
# Google OAuth - Get from https://console.cloud.google.com
GOOGLE_CLIENT_ID=your-google-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your-google-client-secret

# GitHub OAuth - Get from https://github.com/settings/developers
GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret

# ============ Security ============
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SESSION_SECRET=your-random-session-secret-min-32-chars
SECURE_COOKIES=true
CORS_ORIGINS=http://localhost:1431,http://127.0.0.1:1431

# ============ Database (Optional) ============
# For production, use a real database like PostgreSQL
# DATABASE_URL=postgresql://user:password@localhost:5432/q_ide

# ============ LLM Integration (Optional) ============
# OpenAI - Get from https://platform.openai.com
OPENAI_API_KEY=sk-...

# Anthropic Claude - Get from https://console.anthropic.com
ANTHROPIC_API_KEY=sk-ant-...

# Local Ollama (default: http://127.0.0.1:11434)
OLLAMA_BASE_URL=http://127.0.0.1:11434

# LLM Model Selection
LLM_MODEL=gpt-4-turbo
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096

# ============ Additional Configuration ============
# Allowed hosts for Tauri
ALLOWED_HOST=localhost,127.0.0.1

# Optional: Kubelet configuration
KUBEC_SERVER_URL=http://localhost:51821

# Optional: Telemetry (set to false in production if privacy is concern)
ENABLE_TELEMETRY=true
