# ğŸ¤– AI AGENT MARKETPLACE - COMPLETE SPECIFICATION

**Status**: Planning Complete  
**Date**: October 29, 2025  
**Marketplace Model**: Directory (BYOK links; no commissions collected)  
**Timeline**: Week 2-3 (concurrent with IntelliSense + Game Engines)  
**Market Size**: $15B+ AI model services market  

---

## ğŸ¯ VISION

**Problem**: Developers waste time switching between ChatGPT, Claude, Copilot, Gemini, Llama, etc.

**Solution**: Single unified marketplace in Top Dog to:
- âœ… Browse 50+ AI models (free + paid)
- âœ… Sign in with one account
- âœ… Get Q Assistant recommendations ("What model should I use?")
- âœ… Use any model directly inside the IDE
- âœ… Pay only for what you use (or use free models)

**Outcome**: Top Dog becomes the **universal AI agent hub** for developers

---

## ğŸ§­ MARKETPLACE MODE: DIRECTORY (BYOK)

This marketplace operates as a directory and integration hub, not a reseller. We do not collect commissions or re-sell tokens. Users bring their own provider keys (BYOK) and connect them inside Top Dog. Our job is to make discovery easy and integration seamless.

What this means:
- No commission or revenue share is enforced. Listings point to providers' official signâ€‘up pages.
- Top Dog offers a uniform UX (model picker, chat, code tools) on top of your own provider accounts.
- Optional: nonâ€‘production â€œDemoâ€ models hosted by us for trial only (strict quotas, no SLAs).

User flow:
1) Browse models in the Marketplace (Directory)
2) Click â€œGet API Keyâ€ â†’ opens the providerâ€™s official signâ€‘up page
3) Paste your API key into Top Dog (BYOK) and start using models within the IDE

Notes:
- Enterprise remains customerâ€‘managed/selfâ€‘hosted with BYOK only.
- Where available, we may use referral links; these do not affect user pricing or availability.

---

## ğŸ§ª Regulated Segments: Medical & Scientific Pricing

Some marketplace agents/tools operate on regulated or highâ€‘integrity data. Offer segment SKUs with added protections and distinct pricing.

Segments:
- medical (PHI/HIPAA): PHI scrubbing, audit logging, provenance/attestation, data residency controls, stricter SLAs.
- scientific (high-integrity R&D): citation mode, provenance, stricter hallucination limits.

How this appears in Marketplace:
- Model cards and agent listings can declare supported segments (badges: Medical, Scientific).
- Users can choose a segment at project/API-key level; OPA enforces policy at the gateway.

Pricing (illustrative; see MONETIZATION_V2 for formulas):
- Pro-Med: $299/mo, 250k TCU; overage $0.0015/TCU (BYOK discount available)
- Pro-Scientific: $239/mo, 250k TCU; overage $0.0014/TCU
- Enterprise: custom annual with BYOK, private deploy, custom OPA policies

SLAs tied to existing SLIs:
- medical: consistency â‰¥ 0.80; hallucination â‰¤ 0.45
- scientific: consistency â‰¥ 0.78; hallucination â‰¤ 0.55

Billing and metering fields:
- `data_segment` (general|medical|scientific), `verified` (attestation), `policy_pack` and `residency` labels.

---

## ğŸ§© Free Demo Models and API Keys

Purpose: Let users test the marketplace before upgrading. Demo models are strictly nonâ€‘production: rateâ€‘limited, low quotas, and no SLAs. Upgrade to Pro/Enterprise for production throughput and guarantees.

Key properties:
- Issued API keys marked plan="Free" and key_type="demo".
- Perâ€‘key quota (e.g., 200 requests/day), perâ€‘minute rate limit (e.g., 10 rpm).
- Model caps: small openâ€‘source backbones, short context windows.
- Nonâ€‘production Terms: no PHI/PII, no regulated workloads, no external integrations.

Catalog schema (`marketplace/free-models.catalog.json`):
```json
[
  {
    "id": "topdog-demo-7b",
    "name": "TopDog Demo 7B",
    "provider": "topdog",
    "pricing": "free-demo",
    "production": false,
    "quotas": { "daily": 200, "rpm": 10 },
    "limits": { "max_context": 4096, "max_output": 512 },
    "disclaimer": "Demo only. Non-production. Upgrade required for SLAs."
  }
]
```

Gating behaviors:
- Requests with plan="Free" are capped; attempting regulated segments returns policy deny with guidance to upgrade.
- Marketplace UI labels demo models as "Demo (nonâ€‘production)" with a clear path to upgrade.
- Prometheus rules exclude demo models from production SLO reports.

---

## ğŸ—ï¸ ARCHITECTURE

### System Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (React)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”œâ”€ Marketplace Panel (browse, search, filter)          â”‚
â”‚ â”œâ”€ Auth UI (sign-up, sign-in, profile)                 â”‚
â”‚ â”œâ”€ Model Selector (dropdown with recommendations)      â”‚
â”‚ â”œâ”€ Agent Workspace (chat/query UI)                     â”‚
â”‚ â””â”€ Pricing Selector (free vs paid)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BACKEND (Python Flask)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”œâ”€ Auth Service (JWT, user accounts, API keys)         â”‚
â”‚ â”œâ”€ Model Registry (database of all models)             â”‚
â”‚ â”œâ”€ Search/Filter Engine (full-text, faceted)           â”‚
â”‚ â”œâ”€ Recommendation Engine (Q Assistant powered)         â”‚
â”‚ â”œâ”€ API Router (routes to correct LLM provider)         â”‚
â”‚ â”œâ”€ Billing Service (tracks usage, charges)             â”‚
â”‚ â””â”€ Usage Analytics (telemetry, dashboards)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ API INTEGRATIONS (Multi-LLM Support)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”œâ”€ OpenAI (GPT-4, GPT-4 Turbo, GPT-3.5)                â”‚
â”‚ â”œâ”€ Anthropic (Claude 3 Opus/Sonnet/Haiku)              â”‚
â”‚ â”œâ”€ Google (Gemini Pro, PaLM)                           â”‚
â”‚ â”œâ”€ HuggingFace (Llama, Mistral, others)                â”‚
â”‚ â”œâ”€ Custom Providers (Azure, AWS, GCP)                  â”‚
â”‚ â””â”€ Local Ollama (self-hosted models)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Diagram

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q Assistant         â”‚ â† Analyzes task
â”‚ (Recommendation)    â”‚   Suggests best model
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   for this use case
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Marketplace         â”‚ â† User selects model
â”‚ (Model Browser)     â”‚   or uses Q's suggestion
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Authentication      â”‚ â† User signs in
â”‚ (JWT + API Keys)    â”‚   Top Dog gets model token
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Subscription Check  â”‚ â† Verify subscription status
â”‚ (Usage Tracker)     â”‚   and entitlements
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Router              â”‚ â† Route to correct provider
â”‚ (Multi-LLM Adapter)     â”‚   (OpenAI vs Claude vs etc)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  Specific LLM API
    (OpenAI, etc)
         â”‚
         â–¼
    Response
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Subscription/Usage  â”‚ â† Log usage
â”‚ (telemetry only)    â”‚   Provider bills usage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Display Result
     to User
```

---

## ğŸ“ FILE STRUCTURE (8-10 Files)

### Backend Services (4 files, ~1,200 lines)

#### 1. `backend/services/ai_marketplace_registry.py` (320 lines)
**Purpose**: Central model registry & database

```python
class AIModel:
    """Represents a single AI model in marketplace"""
    name: str  # "GPT-4"
    provider: str  # "openai"
    model_id: str  # "gpt-4"
    pricing_tier: str  # "free" | "paid" | "premium"
    cost_per_1k_tokens: float  # 0.03
    context_window: int  # 128000
    capabilities: List[str]  # ["code", "text", "image"]
    description: str
    rating: float  # 1-5
    use_count: int  # popularity metric
    is_available: bool
    regions: List[str]  # ["US", "EU", "ASIA"]

class MarketplaceRegistry:
    """Registry of all available AI models"""
    
    def get_all_models(self) -> List[AIModel]
    def search_models(query: str) -> List[AIModel]
    def filter_models(tier: str, capability: str) -> List[AIModel]
    def get_model_details(model_id: str) -> AIModel
    def add_model(model_data: dict) -> str
    def update_model_status(model_id: str, status: str) -> bool
    def get_popular_models(limit: int) -> List[AIModel]
    def get_new_models(limit: int) -> List[AIModel]
```

**Key Data**:
```python
MODELS = [
    # Free Models
    {"name": "Llama 2 7B", "provider": "huggingface", "cost": 0, "tier": "free"},
    {"name": "Mistral 7B", "provider": "huggingface", "cost": 0, "tier": "free"},
    {"name": "OpenAI GPT-3.5", "provider": "openai", "cost": 0, "tier": "free_trial"},
    
    # Paid Models
    {"name": "GPT-4", "provider": "openai", "cost": 0.03, "tier": "paid"},
    {"name": "Claude 3 Opus", "provider": "anthropic", "cost": 0.015, "tier": "paid"},
    {"name": "Gemini Pro", "provider": "google", "cost": 0.0005, "tier": "paid"},
    {"name": "Mistral Large", "provider": "mistral", "cost": 0.008, "tier": "paid"},
]
```

#### 2. `backend/services/ai_auth_service.py` (280 lines)
**Purpose**: User authentication & API key management

```python
class User:
    """Top Dog user account"""
    user_id: str
    email: str
    password_hash: str
    api_keys: Dict[str, str]  # {"openai": "sk-...", "anthropic": "sk-..."}
    subscription_tier: str  # "free" | "pro" | "enterprise"
    subscription_expires: datetime
    balance: float  # prepaid balance
    created_at: datetime
    updated_at: datetime

class AIAuthService:
    """Manages user auth and API key access"""
    
    def sign_up(email: str, password: str) -> User
    def sign_in(email: str, password: str) -> str  # returns JWT
    def verify_token(token: str) -> User
    def add_api_key(user_id: str, provider: str, api_key: str) -> bool
    def get_api_key(user_id: str, provider: str) -> str
    def refresh_token(old_token: str) -> str
    def get_user_profile(user_id: str) -> User
    def update_subscription(user_id: str, tier: str, duration_months: int) -> bool
    def check_balance(user_id: str) -> float
    def deduct_balance(user_id: str, amount: float) -> bool
```

**Key Features**:
- JWT tokens (expires in 7 days)
- Encrypted API key storage (never exposed to frontend)
- Subscription tiers (free, pro $5/mo, enterprise)
- Prepaid balance system
- GDPR-compliant data handling

#### 3. `backend/services/ai_recommendation_engine.py` (300 lines)
**Purpose**: Q Assistant recommends best model for task

```python
class RecommendationEngine:
    """AI-powered model recommendations"""
    
    def analyze_task(task_description: str) -> Dict[str, any]:
        """
        Analyzes user's task/query to recommend best model
        Input: "I need to debug a complex Python issue"
        Output: {
            "primary_model": "gpt-4",
            "alternatives": ["claude-3-opus", "gemini-pro"],
            "reasoning": "GPT-4 best for code analysis",
            "recommended_tier": "paid",
            "estimated_cost": 0.05
        }
        """
    
    def score_model_for_task(model: AIModel, task: str) -> float:
        """Score 1-10: how well suited is this model?"""
    
    def get_recommendations(user_id: str, task: str, limit: int = 3) -> List[Dict]:
        """Get top N model recommendations for user"""
    
    def learn_from_usage(user_id: str, model_used: str, task_type: str, 
                        satisfaction_score: int):
        """ML: Learn which models users actually prefer"""
    
    def get_trending_models(time_period: str = "week") -> List[AIModel]:
        """Get models trending by usage"""
```

**Recommendation Logic**:
```python
TASK_TO_MODEL_MAPPING = {
    "code_generation": ["gpt-4", "claude-3-opus", "gemini-pro"],
    "code_review": ["gpt-4", "claude-3-opus"],
    "debugging": ["gpt-4"],  # Highest accuracy
    "documentation": ["claude-3-sonnet", "gemini-pro"],
    "brainstorming": ["claude-3-opus", "gpt-4"],
    "quick_task": ["gpt-3.5", "mistral-large"],  # Fast + cheap
    "budget_conscious": ["mistral-7b", "llama-2"],
}
```

#### 4. `backend/services/ai_api_router.py` (300 lines)
**Purpose**: Universal router for all LLM providers

```python
class APIRouter:
    """Routes requests to correct LLM provider"""
    
    def route_completion(user_id: str, model_id: str, prompt: str, 
                        options: dict) -> str:
        """
        Universal interface for completions
        Translates to provider-specific format
        """
    
    def get_openai_completion(api_key: str, prompt: str, model: str) -> str:
        """OpenAI API wrapper"""
    
    def get_anthropic_completion(api_key: str, prompt: str, model: str) -> str:
        """Anthropic API wrapper"""
    
    def get_huggingface_completion(api_key: str, prompt: str, model: str) -> str:
        """HuggingFace API wrapper"""
    
    def get_google_completion(api_key: str, prompt: str, model: str) -> str:
        """Google Gemini API wrapper"""
    
    def get_ollama_completion(prompt: str, model: str, local_url: str) -> str:
        """Local Ollama wrapper (self-hosted)"""
    
    def handle_streaming(user_id: str, model_id: str, prompt: str) -> Stream:
        """Real-time streaming responses"""
    
    def fallback_to_free_model(primary_failed: str) -> str:
        """If paid model fails, try free alternative"""
```

**Provider Adapters**:
```python
PROVIDER_CONFIGS = {
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "models": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
        "timeout": 30
    },
    "anthropic": {
        "base_url": "https://api.anthropic.com",
        "models": ["claude-3-opus", "claude-3-sonnet"],
        "timeout": 60
    },
    "huggingface": {
        "base_url": "https://huggingface.co/api",
        "models": ["meta-llama/Llama-2-7b", "mistral-community/Mistral-7B"],
        "timeout": 30
    },
    "ollama": {
        "base_url": "http://localhost:11434",
        "models": ["llama2", "mistral"],
        "timeout": 60
    }
}
```

### REST API Routes (2 files, ~500 lines)

#### 5. `backend/api/v1/ai_marketplace_routes.py` (280 lines)
**Purpose**: API endpoints for marketplace operations

```python
blueprint = Blueprint('marketplace', __name__, url_prefix='/api/v1/marketplace')

# Endpoints (14 total)

# Authentication (3)
@bp.post('/auth/signup')
@bp.post('/auth/signin')
@bp.post('/auth/logout')

# Browse Models (4)
@bp.get('/models')           # List all models
@bp.get('/models/search')    # Search by name/description
@bp.get('/models/categories') # Filter by capability
@bp.get('/models/<model_id>') # Get model details

# User Management (3)
@bp.get('/profile')          # Get user profile
@bp.post('/api-keys')        # Add/update API key
@bp.get('/api-keys')         # List user's API keys

# Recommendations (2)
@bp.post('/recommendations') # Get Q Assistant recommendations
@bp.get('/trending')         # Get trending models

# Billing (2)
@bp.get('/billing/balance')  # Check account balance
@bp.post('/billing/topup')   # Add prepaid balance
```

#### 6. `backend/api/v1/ai_agent_routes.py` (220 lines)
**Purpose**: API for using AI agents

```python
blueprint = Blueprint('agents', __name__, url_prefix='/api/v1/agents')

# Agent Execution Endpoints (8)

@bp.post('/completion')
"""
Request: {
    "model": "gpt-4",
    "prompt": "Debug this code...",
    "max_tokens": 2000,
    "temperature": 0.7,
    "stream": false
}
Response: {
    "result": "Here's the issue...",
    "tokens_used": 250,
    "cost": 0.0075,
    "model": "gpt-4"
}
"""

@bp.post('/chat')
# Multi-turn conversation

@bp.post('/code-generation')
# Specialized for code gen

@bp.post('/code-review')
# Specialized for code review

@bp.post('/explain')
# Explain code/concepts

@bp.post('/debug')
# Debug assistance

@bp.get('/agents/<agent_id>/history')
# Get conversation history

@bp.delete('/agents/<agent_id>/history')
# Clear history
```

### Frontend UI (3 components, ~1,400 lines)

#### 7. `frontend/components/AIMarketplacePanel.tsx` (550 lines)
**Purpose**: Main marketplace browsing interface

```typescript
interface AIModel {
  id: string;
  name: string;
  provider: string;
  pricing: "free" | "paid" | "premium";
  cost: number;
  rating: number;
  usageCount: number;
  capabilities: string[];
  contextWindow: number;
  description: string;
}

interface AIMarketplacePanelProps {
  onModelSelect: (model: AIModel) => void;
}

export const AIMarketplacePanel: React.FC<AIMarketplacePanelProps> = ({
  onModelSelect
}) => {
  // State
  const [models, setModels] = useState<AIModel[]>([]);
  const [searchQuery, setSearchQuery] = useState("");
  const [selectedTier, setSelectedTier] = useState("all");
  const [filteredModels, setFilteredModels] = useState<AIModel[]>([]);
  const [recommendations, setRecommendations] = useState<AIModel[]>([]);
  const [loading, setLoading] = useState(false);
  const [user, setUser] = useState(null);
  const [showAuthModal, setShowAuthModal] = useState(false);
  
  // Sections:
  // 1. Search bar (with Q Assistant button)
  // 2. Filter sidebar (free/paid, capabilities)
  // 3. Recommended models carousel (Q Assistant suggestions)
  // 4. Popular models section
  // 5. All models grid (searchable, sortable)
  // 6. Model detail card (on hover/click)
  
  return (
    <MarketplaceContainer>
      <Header>
        <Title>ğŸ¤– AI Agent Marketplace</Title>
        <AuthButton>
          {user ? `Signed in as ${user.email}` : "Sign In"}
        </AuthButton>
      </Header>
      
      <SearchSection>
        <SearchInput 
          placeholder="Search models or describe your task..."
          onChange={handleSearch}
        />
        <QAssistantButton 
          onClick={() => getRecommendations(searchQuery)}
        >
          âœ¨ Ask Q Assistant
        </QAssistantButton>
      </SearchSection>
      
      <RecommendedModels>
        {recommendations.map(model => (
          <ModelCard 
            model={model}
            onClick={() => onModelSelect(model)}
          />
        ))}
      </RecommendedModels>
      
      <FilterSection>
        <PricingFilter value={selectedTier} onChange={setSelectedTier} />
        <CapabilityFilter />
        <ProviderFilter />
      </FilterSection>
      
      <ModelsGrid>
        {filteredModels.map(model => (
          <ModelCard key={model.id} model={model} />
        ))}
      </ModelsGrid>
    </MarketplaceContainer>
  );
};
```

#### 8. `frontend/components/AIAuthModal.tsx` (400 lines)
**Purpose**: Sign up / Sign in for marketplace

```typescript
export const AIAuthModal: React.FC<{
  isOpen: boolean;
  onClose: () => void;
  onSuccess: (user: User) => void;
}> = ({ isOpen, onClose, onSuccess }) => {
  const [mode, setMode] = useState<"signin" | "signup">("signin");
  const [email, setEmail] = useState("");
  const [password, setPassword] = useState("");
  const [error, setError] = useState("");
  
  // Tabs: Sign In | Sign Up | Add API Key
  
  // Sign In form:
  // - Email input
  // - Password input
  // - Remember me checkbox
  // - Sign in button
  // - "No account? Sign up" link
  
  // Sign Up form:
  // - Email input
  // - Password input
  // - Confirm password
  // - Terms checkbox
  // - Sign up button
  // - "Already have account? Sign in" link
  
  // Add API Key tab:
  // - Provider selector (OpenAI, Anthropic, etc)
  // - API key input (masked)
  // - Test connection button
  // - Save button
};
```

#### 9. `frontend/components/AIAgentChat.tsx` (450 lines)
**Purpose**: Chat/query interface with selected AI model

```typescript
export const AIAgentChat: React.FC<{
  selectedModel: AIModel;
  user: User;
}> = ({ selectedModel, user }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputValue, setInputValue] = useState("");
  const [loading, setLoading] = useState(false);
  const [balance, setBalance] = useState(0);
  const [showModelInfo, setShowModelInfo] = useState(false);
  
  // Layout:
  // 1. Top bar: Model info | Cost estimate | Balance
  // 2. Chat history
  // 3. Input area with send button
  // 4. Model details panel (on hover)
  
  const handleSendMessage = async (prompt: string) => {
    // 1. Check balance
    // 2. Show loading
    // 3. Stream response from backend
    // 4. Display in chat
    // 5. Update balance
    // 6. Save to history
  };
  
  return (
    <ChatContainer>
      <TopBar>
        <ModelInfo>
          {selectedModel.name}
          <Cost>${selectedModel.cost}/1K tokens</Cost>
          <Balance>${balance.toFixed(2)}</Balance>
        </ModelInfo>
      </TopBar>
      
      <ChatMessages>
        {messages.map(msg => (
          <Message key={msg.id} role={msg.role} content={msg.content} />
        ))}
      </ChatMessages>
      
      <InputArea>
        <textarea 
          value={inputValue}
          onChange={(e) => setInputValue(e.target.value)}
          placeholder="Ask anything..."
        />
        <SendButton onClick={() => handleSendMessage(inputValue)}>
          Send
        </SendButton>
      </InputArea>
    </ChatContainer>
  );
};
```

### Test Suite (1 file, ~400 lines)

#### 10. `backend/tests/test_ai_marketplace.py` (400 lines)
**Purpose**: Comprehensive marketplace testing

```python
class TestMarketplaceRegistry(unittest.TestCase):
    """Test model registry"""
    
    def test_get_all_models(self)
    def test_search_models(self)
    def test_filter_by_pricing(self)
    def test_filter_by_capability(self)

class TestAuthService(unittest.TestCase):
    """Test authentication"""
    
    def test_user_signup(self)
    def test_user_signin(self)
    def test_jwt_token_generation(self)
    def test_api_key_storage(self)
    def test_api_key_encryption(self)

class TestRecommendationEngine(unittest.TestCase):
    """Test recommendations"""
    
    def test_analyze_task_code_generation(self)
    def test_analyze_task_debugging(self)
    def test_score_model_for_task(self)
    def test_trending_models(self)

class TestAPIRouter(unittest.TestCase):
    """Test multi-LLM routing"""
    
    def test_route_to_openai(self)
    def test_route_to_anthropic(self)
    def test_route_to_huggingface(self)
    def test_fallback_on_error(self)
    def test_streaming_response(self)

class TestBillingService(unittest.TestCase):
    """Test billing & balance tracking"""
    
    def test_calculate_token_cost(self)
    def test_deduct_balance(self)
    def test_insufficient_balance_error(self)
    def test_billing_history(self)
```

---

## ğŸ¯ KEY FEATURES BREAKDOWN

### Feature 1: Universal Model Browser
```
Browsing a model in Top Dog:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPT-4 Turbo                             â”‚
â”‚ â­ 4.8 (2,341 reviews)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Provider: OpenAI                        â”‚
â”‚ Context: 128K tokens                    â”‚
â”‚ Speed: âš¡âš¡âš¡âš¡ (very fast)              â”‚
â”‚ Cost: $0.03 per 1K tokens               â”‚
â”‚ Best for: Code, complex reasoning       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Select Model] [View Details]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

vs

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Llama 2 7B                              â”‚
â”‚ â­ 4.2 (1,203 reviews)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Provider: HuggingFace (Free)            â”‚
â”‚ Context: 4K tokens                      â”‚
â”‚ Speed: âš¡âš¡ (medium)                    â”‚
â”‚ Cost: FREE                              â”‚
â”‚ Best for: Quick tasks, budget           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Select Model] [View Details]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feature 2: Q Assistant Recommendations

**User asks Q Assistant**: "I'm building a REST API, what model should I use?"

**Q Assistant analyzes**:
- Task type: "API documentation + code generation"
- Budget: (checks user balance)
- Speed requirement: "Medium (not real-time)"
- Capability needs: "Code generation, REST API expertise"

**Q Assistant recommends**:
```
1. âœ… PRIMARY: Claude 3 Opus
   - Best for: API design (has specific knowledge)
   - Cost: $0.015/1K tokens
   - Reasoning: "Specialized in REST API architecture"

2. ALTERNATIVE: GPT-4 Turbo
   - Cost: $0.03/1K tokens
   - Reasoning: "More powerful but pricier"

3. BUDGET: Mistral Large
   - Cost: $0.008/1K tokens (cheaper)
   - Reasoning: "Good for quick API code"

4. FREE: Llama 2 13B
   - Cost: $0 (free)
   - Reasoning: "Fast for simple endpoints, not API design"
```

### Feature 3: Unified Authentication

```
First Login Flow:
1. User clicks "Sign In" in Marketplace
2. Email/Password authentication
3. (Optional) Add API keys for models:
   - OpenAI key (for GPT-4 access)
   - Anthropic key (for Claude access)
   - etc.
4. Set subscription tier:
   - Free: 3 free model calls/day
   - Pro ($5/mo): Unlimited free models
   - Enterprise: Custom usage limits
5. Add payment method (Stripe)
6. Bookmarked in IDE for future use

Future logins: Just click marketplace â†’ Already authenticated!
```

### Feature 4: Seamless Model Switching

```
User workflow:

1. Opens AI Agent Marketplace panel
2. Sees Q Assistant recommended models
3. Clicks "Use Claude 3 Opus"
4. Automatically:
   âœ… Loads Claude 3 API key from secure storage
   âœ… Checks user balance
   âœ… Opens chat interface with Claude
   âœ… User starts typing queries
5. All responses streamed live in IDE
6. Cost tracked and deducted automatically
7. User switches to GPT-4 for next query (1 click)
```

### Feature 5: Cost Transparency

```
Chat interface shows:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’° Account Balance: $45.32   â”‚
â”‚ ğŸ“Š This month usage: $8.47   â”‚
â”‚ â±ï¸  Avg response cost: $0.03  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model: GPT-4 Turbo           â”‚
â”‚ This query: 234 tokens â‰ˆ$0.007â”‚
â”‚ Your balance after: $45.31   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query input: [User types...]
[Send] [Add $10] [View billing history]
```

---

## ğŸ”— INTEGRATION POINTS

### 1. Q Assistant Integration
```python
# When user asks Q Assistant a question:
@route('/api/v1/q-assistant/help')
def ask_q_assistant(query: str):
    # 1. Understand user's task
    task_analysis = analyze_task(query)
    
    # 2. Get recommended models
    recommendations = recommendation_engine.get_recommendations(
        task=task_analysis,
        user_budget=user.balance,
        user_preferences=user.preferences
    )
    
    # 3. Return recommendations to marketplace
    return {
        "recommendations": recommendations,
        "explanation": "Here's why I recommend these models..."
    }
```

### 2. Editor Integration
```typescript
// In Editor.tsx, add AI panel:
<Tabs>
  <Tab name="Code">
    {/* existing code editor */}
  </Tab>
  
  <Tab name="AI Agents">
    {/* NEW: AI marketplace + chat */}
    <AIMarketplacePanel />
  </Tab>
  
  <Tab name="Terminal">
    {/* existing terminal */}
  </Tab>
</Tabs>
```

### 3. Billing System
```python
# Every API call:
1. Check user balance
2. Estimate tokens/cost
3. Execute query
4. Count actual tokens
5. Deduct from balance
6. Log transaction
7. If balance < $1: Warn user
```

---

## ğŸ“Š IMPLEMENTATION TIMELINE

### Week 1-2 (Concurrent with IntelliSense + Game Engines)

**Day 1-2: Backend Foundation**
- âœ… Create AI registry database (120 lines)
- âœ… Create auth service (280 lines)
- Deploy test database

**Day 2-3: Recommendations + Routing**
- âœ… Recommendation engine (300 lines)
- âœ… Multi-LLM API router (300 lines)
- Test all provider integrations

**Day 3-4: REST API**
- âœ… Marketplace routes (280 lines)
- âœ… Agent routes (220 lines)
- API testing (50 routes)

**Day 4-5: Frontend UI**
- âœ… Marketplace panel (550 lines)
- âœ… Auth modal (400 lines)
- âœ… Agent chat UI (450 lines)
- Styling & polish

**Day 5: Testing + Validation**
- âœ… Unit tests (400 lines)
- âœ… E2E tests
- Performance benchmarks
- All tests passing

### Week 2-3 (Phase 2)

**Week 2**: Add more models + payment integration
- Stripe integration
- Model partnerships (OpenAI, Anthropic, etc)
- Usage analytics dashboard

**Week 3**: Market launch
- Beta marketplace launch
- First 1,000 users
- Gathering feedback

---

## ğŸš€ LAUNCH CHECKLIST

- [ ] Backend complete (4 files, 1,200+ lines)
- [ ] Frontend complete (3 components, 1,400+ lines)
- [ ] All 10+ tests passing
- [ ] API integrations working (OpenAI, Anthropic, etc)
- [ ] Auth working (sign-up, sign-in, API keys)
- [ ] Recommendations working (Q Assistant)
- [ ] Billing tracking working
- [ ] Performance < 500ms per query
- [ ] Security audit (API key encryption, JWT validation)
- [ ] Documentation complete
- [ ] Beta users onboarded
- [ ] Revenue tracking working (30% commission)

---

## ğŸ’¡ COMPETITIVE ADVANTAGES

### vs ChatGPT Direct
- âœ… Don't leave IDE
- âœ… Access 50+ models, not just GPT
- âœ… One authentication, all models
- âœ… Q Assistant recommendations
- âœ… Integrated billing (30% cheaper)

### vs GitHub Copilot
- âœ… 50+ models, not just 1
- âœ… User picks which model for each task
- âœ… Transparent pricing
- âœ… Supports local/self-hosted models
- âœ… Works with all game engines

### vs VS Code + Extensions
- âœ… All in one UI
- âœ… Recommendations built-in
- âœ… Billing unified
- âœ… Marketplace first-class feature
- âœ… Supporting game engines (unique)

---

## ğŸ“ˆ REVENUE PROJECTIONS

### Year 1 Phase 1 (Launch)
- Beta users: 5,000
- Adoption rate: 30% use paid models
- Avg spend: $50/month
- Commission (30%): $22.5k MRR

### Year 1 Phase 2 (Month 6)
- Active users: 50,000
- Adoption rate: 40%
- Avg spend: $200/month
- Commission (30%): **$120k MRR**
- Subscriptions: +$20k MRR
- **Total: $140k MRR**

### Year 1 Phase 3 (Month 12)
- Active users: 150,000
- Adoption rate: 50%
- Avg spend: $300/month
- Commission (30%): $675k MRR
- Subscriptions: +$50k MRR
- Enterprise: +$50k MRR
- **Total: $775k MRR**

**ROI**: Invest $200k dev time â†’ Generate $9.3M/year revenue (Year 1)

---

## âœ… SUCCESS METRICS

- **Adoption**: 50%+ of Top Dog users have tried marketplace in first 30 days
- **Usage**: Average user tries 3+ models in first week
- **Revenue**: $100k+ MRR by month 6 of launch
- **Satisfaction**: 4.5+ star rating on marketplace models
- **Retention**: 60%+ of first-month users still active 3 months later
- **Performance**: Model selection + query execution < 500ms
- **Uptime**: 99.9% availability
- **Security**: Zero API key breaches

---

## ğŸ‰ FINAL IMPACT

**Top Dog becomes the universal hub for developers to:**
- ğŸ® Build games (4 engines)
- ğŸ¤– Use any AI model (50+ models)
- ğŸ’» Code with IDE features (IntelliSense, refactoring, debugging)
- ğŸš€ Launch products faster

**Competitive Position**: #1 Developer IDE combining code + game engines + AI agents

**Revenue**: $775k+ MRR by end of Year 1

**Market Share**: 20-30% of $15B AI model services market

---

**Status**: Ready to build  
**Start Date**: Week of Nov 3, 2025  
**Target Launch**: Dec 15, 2025  
**Priority**: HIGH (Gap #5 - AI Agent Marketplace)

